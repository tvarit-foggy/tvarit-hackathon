{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray\n",
      "  Downloading ray-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (22.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.9 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (3.0.12)\n",
      "Collecting aioredis\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 9.2 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (0.4.3)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 118.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.7.10-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 123.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 101.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting redis<3.5.0,>=3.3.2\n",
      "  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (7.0)\n",
      "Collecting gpustat\n",
      "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 17.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (0.7.1)\n",
      "Collecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 8.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (3.2.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 92.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 110.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray) (2.22.0)\n",
      "Collecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 79.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting opencensus-context==0.1.1\n",
      "  Downloading opencensus_context-0.1.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.22.4-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 3.5 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gpustat->ray) (1.14.0)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from gpustat->ray) (5.6.7)\n",
      "Collecting blessings>=1.6\n",
      "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->ray) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google->ray) (4.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema->ray) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema->ray) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jsonschema->ray) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray) (3.7.4.3)\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (257 kB)\n",
      "\u001b[K     |████████████████████████████████| 257 kB 113.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<5.0,>=4.5\n",
      "  Downloading multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 113.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->ray) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->ray) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->ray) (2.8)\n",
      "Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2019.3)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 23.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2.0dev,>=1.21.1\n",
      "  Downloading google_auth-1.22.1-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 121.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: soupsieve>=1.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from beautifulsoup4->google->ray) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray) (2.2.0)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 2.2 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 123.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.5)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: gpustat, nvidia-ml-py3, idna-ssl, contextvars\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=17ed5d266eac5f65705e9ca3ca440fe0fde54fa88e9ff705d9ea12c2d6d19bc4\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/50/da/35/fe2cfb3bc47822299f5e124a599d56f00b30ec0b328db16b9f\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19189 sha256=886140e3450a2771c092b0e81bb681368b5b85d2fb62442d47c5761165eeb6de\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7f/26/a3/33f2079871e2bebb3f53a2b21c3ec64129b8efdd18a6263a52\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=6ff9f05bb3a82c3cd0ede90c92438e6e66728f05b114536118387aa08ce60dce\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7664 sha256=32b8837c2cc2be4cd1482aeaa5209d1d5e6b27c54849253b25f31e8a2cceb517\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built gpustat nvidia-ml-py3 idna-ssl contextvars\n",
      "Installing collected packages: hiredis, async-timeout, aioredis, msgpack, immutables, contextvars, opencensus-context, googleapis-common-protos, pyasn1-modules, cachetools, google-auth, google-api-core, opencensus, py-spy, redis, nvidia-ml-py3, blessings, gpustat, google, idna-ssl, multidict, yarl, aiohttp, aiohttp-cors, colorful, grpcio, ray\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 0.6.1\n",
      "    Uninstalling msgpack-0.6.1:\n",
      "      Successfully uninstalled msgpack-0.6.1\n",
      "Successfully installed aiohttp-3.6.2 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 cachetools-4.1.1 colorful-0.5.4 contextvars-2.4 google-3.0.0 google-api-core-1.22.4 google-auth-1.22.1 googleapis-common-protos-1.52.0 gpustat-0.6.0 grpcio-1.32.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 msgpack-1.0.0 multidict-4.7.6 nvidia-ml-py3-7.352.0 opencensus-0.7.10 opencensus-context-0.1.1 py-spy-0.3.3 pyasn1-modules-0.2.8 ray-1.0.0 redis-3.4.1 yarl-1.6.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tb-nightly\n",
      "  Downloading tb_nightly-2.4.0a20201009-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 8.0 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (0.34.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (1.19.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (1.14.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (3.13.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 106.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (1.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tb-nightly) (1.22.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 85.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tb-nightly) (1.7.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly) (2.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly) (4.5)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly) (2.2.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 109.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly) (0.4.8)\n",
      "Installing collected packages: markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, tensorboard-plugin-wit, tb-nightly\n",
      "Successfully installed absl-py-0.10.0 google-auth-oauthlib-0.4.1 markdown-3.3 oauthlib-3.1.0 requests-oauthlib-1.3.0 tb-nightly-2.4.0a20201009 tensorboard-plugin-wit-1.7.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.7\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create train, valid, test iterators for CIFAR-10 [1].\n",
    "Easily extended to MNIST, CIFAR-100 and Imagenet.\n",
    "[1]: https://discuss.pytorch.org/t/feedback-on-pytorch-for-kaggle-competitions/2252/4\n",
    "\"\"\"\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \"\"\"\n",
    "    Adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # plot img\n",
    "        ax.imshow(images[i, :, :, :], interpolation='spline16')\n",
    "\n",
    "        # show true & predicted classes\n",
    "        cls_true_name = label_names[cls_true[i]]\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"{0} ({1})\".format(cls_true_name, cls_true[i])\n",
    "        else:\n",
    "            cls_pred_name = label_names[cls_pred[i]]\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(\n",
    "                cls_true_name, cls_pred_name\n",
    "            )\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=9, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory,\n",
    "        )\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy().transpose([0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "\n",
    "    loaders = {\"Train\":train_loader, \"Valid\":valid_loader} \n",
    "    dataset_sizes = {\"Train\": len(train_dataset), \"Valid\": len(train_dataset) * valid_size}\n",
    "    return loaders, dataset_sizes\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4,\n",
    "                    pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning a multi-process\n",
    "    test iterator over the CIFAR-10 dataset.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - shuffle: whether to shuffle the dataset after every epoch.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - data_loader: test set iterator.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    loader = {\"Test\":data_loader}\n",
    "    dataset_sizes = {\"Test\": len(dataset)}\n",
    "    return loader, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_model(model, device, dataloaders, dataset_sizes, criterion, optimizer, tb_logger, num_epochs, scheduler=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['Train', 'Valid']:\n",
    "            if phase == 'Train':\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # DEVICE --> where the computation is happening\n",
    "                # Torch.dtypes --> cuda tensors, cpu tensors\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'Train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            #Log with Tensorboard\n",
    "            if phase=='Train':\n",
    "                tb_logger.add_scalar('train_Loss',float(epoch_loss), epoch+1)\n",
    "                tb_logger.add_scalar('train_Accuracy', float(epoch_acc), epoch+1)\n",
    "            elif phase=='Valid':\n",
    "                tb_logger.add_scalar('valid_Loss',float(epoch_loss), epoch+1)\n",
    "                tb_logger.add_scalar('valid_Accuracy', float(epoch_acc), epoch+1)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'Valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, epoch_loss, best_acc\n",
    "\n",
    "def test_model(model, device, dataloaders, dataset_sizes, criterion):\n",
    "\n",
    "    since = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phase in ['Test']:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Test Acc: {:4f}'.format(epoch_acc))\n",
    "\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, c1=32, c2=64, c3=64, l1=64):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(3, c1, 3)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('pool1', nn.MaxPool2d(2,2)),\n",
    "          ('conv2', nn.Conv2d(c1,c2,3)),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('pool2', nn.MaxPool2d(2,2)),\n",
    "          ('conv3', nn.Conv2d(c2,64,3)),\n",
    "          ('relu3', nn.ReLU()),\n",
    "          ('flatten', nn.Flatten())\n",
    "        ]))\n",
    "        self.fc_block = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(1024, l1)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(l1, 10))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, checkpoint_dir = None, data_dir=\"./data\"):\n",
    "\n",
    "    net = Net(config[\"c1\"], config[\"c2\"], config[\"c3\"], config[\"l1\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = None\n",
    "    if config[\"optim\"] == \"SGD\":\n",
    "        optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    elif config[\"optim\"] == \"Adam\":\n",
    "        optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    augment=False\n",
    "    valid_size=0.2\n",
    "    shuffle=True\n",
    "    trainloaders, train_dataset_sizes = get_train_valid_loader(data_dir=data_dir, batch_size=config[\"batchsize\"],\n",
    "                       augment=augment, random_seed=SEED, valid_size=valid_size,\n",
    "                       shuffle=shuffle, show_sample=False, num_workers=8, pin_memory=True)\n",
    "    testloader, test_dataset_sizes = get_test_loader(data_dir=data_dir, batch_size=64, shuffle=False,\n",
    "                             num_workers=8, pin_memory=True)\n",
    "    \n",
    "    tb_logger = SummaryWriter(os.path.join(LOG_DIR,\"test_exp2\"))\n",
    "    num_epochs = 10\n",
    "\n",
    "    model, val_loss, val_acc = train_model(net, device, trainloaders, train_dataset_sizes, criterion, optimizer, tb_logger, num_epochs)\n",
    "    \n",
    "    test_acc = test_model(net, device, testloader, test_dataset_sizes, criterion)\n",
    "\n",
    "    tune.report(loss=val_loss, accuracy=val_acc)\n",
    "    tb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    # load_data(data_dir)  # Download data for all trials before starting the run\n",
    "    config = {\n",
    "        \"c1\": tune.choice([16, 32, 64]),\n",
    "        \"c2\": tune.choice([32, 64, 128]),\n",
    "        \"c3\": tune.choice([64, 128, 256]),        \n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batchsize\": tune.choice([16, 32, 64,]),\n",
    "        \"optim\": tune.choice([\"Adam\"]),\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"c1\"], best_trial.config[\"c2\"],\n",
    "                            best_trial.config[\"c3\"], best_trial.config[\"l1\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_trial.checkpoint.value, \"checkpoint\")\n",
    "\n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    testloader, test_dataset_sizes = get_test_loader(data_dir=data_dir, batch_size=64, shuffle=False,\n",
    "                             num_workers=8, pin_memory=True)\n",
    "    test_acc = test_model(best_trained_model, device, testloader, test_dataset_sizes, criterion)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = 'runs'\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-10 12:20:49,471\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-10-10 12:20:50,591\tWARNING experiment.py:256 -- No name detected on trainable. Using DEFAULT.\n",
      "2020-10-10 12:20:50,593\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n",
      "2020-10-10 12:20:50,627\tINFO logger.py:201 -- pip install 'ray[tune]' to see TensorBoard files.\n",
      "2020-10-10 12:20:50,628\tWARNING logger.py:343 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 1.4/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | RUNNING  |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | PENDING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | PENDING  |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | PENDING  |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | PENDING  |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | PENDING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | PENDING  |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | PENDING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | PENDING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | PENDING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 1.5114 Acc: 0.2305\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 1.5088 Acc: 0.2498\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.5423 Acc: 0.4086\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 1.3916 Acc: 0.2903\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 1.5684 Acc: 0.4252\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 1.4556 Acc: 0.2631\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 1.4488 Acc: 0.4800\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 1.5011 Acc: 0.4537\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 1.3474 Acc: 0.3002\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.6017 Acc: 0.1542\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 1.1621 Acc: 0.3643\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 1.2838 Acc: 0.5380\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.8839 Acc: 0.2137\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.3084 Acc: 0.5128\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 1.1861 Acc: 0.3677\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 1.3560 Acc: 0.5159\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 1.0425 Acc: 0.4272\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 1.2176 Acc: 0.5635\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 1.1058 Acc: 0.3989\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 1.3099 Acc: 0.5301\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 1.3566 Acc: 0.2823\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 1.0213 Acc: 0.4186\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.2160 Acc: 0.5522\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 1.0402 Acc: 0.4281\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.4135 Acc: 0.4634\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 1.2069 Acc: 0.5684\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.8948 Acc: 0.4850\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 1.0612 Acc: 0.6256\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.9335 Acc: 0.4651\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.4874 Acc: 0.1781\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.9564 Acc: 0.4572\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 1.1668 Acc: 0.5842\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.9248 Acc: 0.4584\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 1.0557 Acc: 0.6197\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.8144 Acc: 0.2411\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.1510 Acc: 0.5850\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.9326 Acc: 0.4694\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 1.1119 Acc: 0.6077\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 1.2087 Acc: 0.3594\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.7917 Acc: 0.5235\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.9703 Acc: 0.6585\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 1.2039 Acc: 0.5713\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.8486 Acc: 0.4890\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.0857 Acc: 0.6135\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.8577 Acc: 0.4982\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 1.0301 Acc: 0.6414\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.8469 Acc: 0.5021\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 1.0328 Acc: 0.6360\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.7928 Acc: 0.5187\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.4462 Acc: 0.1980\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.7122 Acc: 0.5524\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.9525 Acc: 0.6617\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.7878 Acc: 0.5147\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.8269 Acc: 0.2595\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.9591 Acc: 0.6664\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.0669 Acc: 0.6169\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 1.0951 Acc: 0.3946\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.7770 Acc: 0.5262\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.3073 Acc: 0.5334\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.7727 Acc: 0.5271\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 1.0354 Acc: 0.6367\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 0.9830 Acc: 0.6542\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.7365 Acc: 0.5330\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.0235 Acc: 0.6446\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.6501 Acc: 0.5745\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.8963 Acc: 0.6840\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.7129 Acc: 0.5494\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 0.9735 Acc: 0.6636\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.7166 Acc: 0.5485\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.7038 Acc: 0.5508\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.4149 Acc: 0.2092\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 0.9348 Acc: 0.6748\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.9122 Acc: 0.6783\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7518 Acc: 0.2697\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.6903 Acc: 0.5500\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 1.0225 Acc: 0.6473\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.5995 Acc: 0.5908\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.8984 Acc: 0.6961\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.6576 Acc: 0.5698\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 0.9177 Acc: 0.6834\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.6498 Acc: 0.5651\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.6635 Acc: 0.5676\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 0.9773 Acc: 0.6652\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 0.9438 Acc: 0.6732\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.8790 Acc: 0.4875\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.9783 Acc: 0.4538\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.5539 Acc: 0.6066\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.2362 Acc: 0.5672\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.8949 Acc: 0.6976\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.6398 Acc: 0.5727\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.9823 Acc: 0.6497\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3919 Acc: 0.2204\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.6058 Acc: 0.5855\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 0.9108 Acc: 0.6857\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.8661 Acc: 0.7014\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7409 Acc: 0.2615\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Train Loss: 0.6136 Acc: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m 2020-10-10 12:33:06,925\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m \n",
      "2020-10-10 12:33:06,980\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10248, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10248, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Valid Loss: 0.9780 Acc: 0.6682\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Training complete in 12m 12s\n",
      "\u001b[2m\u001b[36m(pid=10248)\u001b[0m Best val Acc: 0.668200\n",
      "== Status ==\n",
      "Memory usage on this node: 7.1/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (1 ERROR, 2 PENDING, 7 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | RUNNING  |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | RUNNING  |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | RUNNING  |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | RUNNING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | RUNNING  |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | PENDING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | PENDING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 1\n",
      "+---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                         |\n",
      "|---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "+---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.6185 Acc: 0.5833\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 0.8524 Acc: 0.7031\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.5163 Acc: 0.6203\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Train Loss: 0.5572 Acc: 0.6033\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.8937 Acc: 0.6972\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m 2020-10-10 12:34:08,392\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m \n",
      "2020-10-10 12:34:08,426\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10257, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10257, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Valid Loss: 0.9159 Acc: 0.6945\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Training complete in 13m 13s\n",
      "\u001b[2m\u001b[36m(pid=10257)\u001b[0m Best val Acc: 0.694500\n",
      "== Status ==\n",
      "Memory usage on this node: 7.0/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (2 ERROR, 1 PENDING, 7 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | RUNNING  |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | RUNNING  |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | RUNNING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | RUNNING  |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | RUNNING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | PENDING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 2\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 1/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.9174 Acc: 0.0786\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3090 Acc: 0.1015\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.5818 Acc: 0.5939\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.5864 Acc: 0.5936\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3731 Acc: 0.2244\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 0.8870 Acc: 0.7001\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.8800 Acc: 0.6999\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7209 Acc: 0.2949\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Train Loss: 0.4764 Acc: 0.6337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m 2020-10-10 12:35:26,420\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m \n",
      "2020-10-10 12:35:26,508\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00006: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10247, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10247, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Valid Loss: 0.9240 Acc: 0.6929\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Training complete in 14m 31s\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m Best val Acc: 0.697600\n",
      "== Status ==\n",
      "Memory usage on this node: 6.9/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (3 ERROR, 7 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | RUNNING  |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | RUNNING  |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | RUNNING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | RUNNING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 3\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8472 Acc: 0.0804\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3149 Acc: 0.1023\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.9139 Acc: 0.4813\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.1424 Acc: 0.6128\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Train Loss: 0.5410 Acc: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m 2020-10-10 12:36:24,350\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m \n",
      "2020-10-10 12:36:24,539\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10246, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10246, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Valid Loss: 0.8793 Acc: 0.7007\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Training complete in 15m 29s\n",
      "\u001b[2m\u001b[36m(pid=10246)\u001b[0m Best val Acc: 0.703100\n",
      "== Status ==\n",
      "Memory usage on this node: 6.1/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 6/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (4 ERROR, 6 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | RUNNING  |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | RUNNING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | RUNNING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 4\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8253 Acc: 0.0940\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8474 Acc: 0.0786\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3134 Acc: 0.0978\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 2/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3083 Acc: 0.1023\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.5423 Acc: 0.6078\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3566 Acc: 0.2308\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.8432 Acc: 0.7122\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7125 Acc: 0.2850\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.7339 Acc: 0.5440\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8474 Acc: 0.0795\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3051 Acc: 0.0996\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.9116 Acc: 0.6793\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8495 Acc: 0.0805\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8468 Acc: 0.0806\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3222 Acc: 0.1023\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.8663 Acc: 0.5043\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3072 Acc: 0.0996\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 3/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3382 Acc: 0.2363\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.5012 Acc: 0.6219\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7043 Acc: 0.2779\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.8577 Acc: 0.7054\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.1455 Acc: 0.6119\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8471 Acc: 0.0806\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3085 Acc: 0.0973\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8472 Acc: 0.0803\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3230 Acc: 0.2395\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.4624 Acc: 0.6346\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3045 Acc: 0.1015\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8494 Acc: 0.0794\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7064 Acc: 0.3078\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.8733 Acc: 0.7114\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3073 Acc: 0.0973\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 4/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8474 Acc: 0.0799\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.8266 Acc: 0.5189\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3048 Acc: 0.0994\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.6485 Acc: 0.5731\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.0789 Acc: 0.6414\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.8738 Acc: 0.6977\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Train Loss: 1.3149 Acc: 0.2398\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Train Loss: 0.4269 Acc: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m 2020-10-10 12:42:31,075\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m \n",
      "2020-10-10 12:42:31,208\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10256, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10256, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Valid Loss: 1.7119 Acc: 0.3176\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Training complete in 21m 36s\n",
      "\u001b[2m\u001b[36m(pid=10256)\u001b[0m Best val Acc: 0.317600\n",
      "== Status ==\n",
      "Memory usage on this node: 5.7/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (5 ERROR, 5 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | RUNNING  |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | RUNNING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 5\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8468 Acc: 0.0805\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3079 Acc: 0.0996\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-10 12:42:38,274\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00005: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10251, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10251, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m 2020-10-10 12:42:38,251\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 4.8/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (6 ERROR, 4 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | RUNNING  |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 6\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Valid Loss: 0.9111 Acc: 0.7080\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Training complete in 21m 43s\n",
      "\u001b[2m\u001b[36m(pid=10251)\u001b[0m Best val Acc: 0.712200\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8490 Acc: 0.0798\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3069 Acc: 0.1040\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 5/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Train Loss: 1.8468 Acc: 0.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m 2020-10-10 12:43:25,651\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m \n",
      "2020-10-10 12:43:25,741\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00008: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=16765, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=16765, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Valid Loss: 2.3148 Acc: 0.0979\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Training complete in 10m 13s\n",
      "\u001b[2m\u001b[36m(pid=16765)\u001b[0m Best val Acc: 0.102300\n",
      "== Status ==\n",
      "Memory usage on this node: 4.0/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 3/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (7 ERROR, 3 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | RUNNING  |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | ERROR    |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 7\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00008 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00008_8_batchsize=16,c1=16,c2=64,c3=256,l1=256,lr=0.03331,optim=Adam_2020-10-10_12-33-07/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.7982 Acc: 0.5330\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.1003 Acc: 0.6389\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8492 Acc: 0.0791\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3189 Acc: 0.0933\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.5839 Acc: 0.5968\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.8262 Acc: 0.7166\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 6/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8497 Acc: 0.0788\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3059 Acc: 0.0973\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.7729 Acc: 0.5431\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.1778 Acc: 0.6108\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8494 Acc: 0.0800\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3113 Acc: 0.1017\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.7596 Acc: 0.5489\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.0948 Acc: 0.6513\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.5297 Acc: 0.6145\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.8604 Acc: 0.7076\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 7/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8492 Acc: 0.0797\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3084 Acc: 0.1030\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Train Loss: 0.7465 Acc: 0.5502\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8493 Acc: 0.0799\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3124 Acc: 0.0979\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m 2020-10-10 12:49:58,678\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m \n",
      "2020-10-10 12:49:58,772\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10249, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10249, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Valid Loss: 1.2045 Acc: 0.6286\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Training complete in 29m 3s\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m Best val Acc: 0.651300\n",
      "== Status ==\n",
      "Memory usage on this node: 3.4/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (8 ERROR, 2 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | ERROR    |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | ERROR    |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | RUNNING  |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 8\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00001 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00001_1_batchsize=4,c1=64,c2=128,c3=128,l1=4,lr=0.0024119,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00008 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00008_8_batchsize=16,c1=16,c2=64,c3=256,l1=256,lr=0.03331,optim=Adam_2020-10-10_12-33-07/error.txt    |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.4782 Acc: 0.6314\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Train Loss: 1.8500 Acc: 0.0750\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.9250 Acc: 0.7049\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 8/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m 2020-10-10 12:51:13,563\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m \n",
      "2020-10-10 12:51:13,608\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00009: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=17254, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=17254, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Valid Loss: 2.3054 Acc: 0.1030\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Training complete in 16m 59s\n",
      "\u001b[2m\u001b[36m(pid=17254)\u001b[0m Best val Acc: 0.104000\n",
      "== Status ==\n",
      "Memory usage on this node: 2.5/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (9 ERROR, 1 RUNNING)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | ERROR    |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | RUNNING  |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | ERROR    |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | ERROR    |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 9\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00001 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00001_1_batchsize=4,c1=64,c2=128,c3=128,l1=4,lr=0.0024119,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00008 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00008_8_batchsize=16,c1=16,c2=64,c3=256,l1=256,lr=0.03331,optim=Adam_2020-10-10_12-33-07/error.txt    |\n",
      "| DEFAULT_08cf9_00009 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00009_9_batchsize=4,c1=32,c2=64,c3=128,l1=16,lr=0.015802,optim=SGD_2020-10-10_12-34-08/error.txt      |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.4375 Acc: 0.6472\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.8673 Acc: 0.7185\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 9/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.4005 Acc: 0.6600\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.8810 Acc: 0.7169\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Epoch 10/10\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m ----------\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Train Loss: 0.3625 Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m 2020-10-10 12:58:23,632\tERROR function_runner.py:233 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 246, in run\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m     output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m   File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m NameError: name 'best_model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m \n",
      "2020-10-10 12:58:23,691\tERROR trial_runner.py:567 -- Trial DEFAULT_08cf9_00007: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10255, ip=172.16.1.33)\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 340, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 459, in _report_thread_runner_error\n",
      "    .format(err_tb_str)))\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10255, ip=172.16.1.33)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 227, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 290, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 499, in _trainable_func\n",
      "    output = train_func(config, checkpoint_dir=checkpoint_dir)\n",
      "  File \"<ipython-input-6-4caa60c98e21>\", line 39, in train\n",
      "  File \"<ipython-input-4-fcba8162403f>\", line 76, in train_model\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Valid Loss: 0.9255 Acc: 0.7190\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Training complete in 37m 28s\n",
      "\u001b[2m\u001b[36m(pid=10255)\u001b[0m Best val Acc: 0.719000\n",
      "== Status ==\n",
      "Memory usage on this node: 1.7/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (10 ERROR)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | ERROR    |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | ERROR    |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | ERROR    |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | ERROR    |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 10\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00001 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00001_1_batchsize=4,c1=64,c2=128,c3=128,l1=4,lr=0.0024119,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00007 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00007_7_batchsize=2,c1=32,c2=128,c3=64,l1=16,lr=0.00026208,optim=Adam_2020-10-10_12-20-50/error.txt   |\n",
      "| DEFAULT_08cf9_00008 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00008_8_batchsize=16,c1=16,c2=64,c3=256,l1=256,lr=0.03331,optim=Adam_2020-10-10_12-33-07/error.txt    |\n",
      "| DEFAULT_08cf9_00009 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00009_9_batchsize=4,c1=32,c2=64,c3=128,l1=16,lr=0.015802,optim=SGD_2020-10-10_12-34-08/error.txt      |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 1.7/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.64 GiB heap, 0.0/2.98 GiB objects\n",
      "Result logdir: /home/ec2-user/ray_results/DEFAULT\n",
      "Number of trials: 10 (10 ERROR)\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "| Trial name          | status   | loc   |   batchsize |   c1 |   c2 |   c3 |   l1 |          lr | optim   |\n",
      "|---------------------+----------+-------+-------------+------+------+------+------+-------------+---------|\n",
      "| DEFAULT_08cf9_00000 | ERROR    |       |           8 |   32 |   32 |  256 |   64 | 0.00050722  | SGD     |\n",
      "| DEFAULT_08cf9_00001 | ERROR    |       |           4 |   64 |  128 |  128 |    4 | 0.00241188  | SGD     |\n",
      "| DEFAULT_08cf9_00002 | ERROR    |       |          16 |   16 |  128 |  256 |  256 | 0.000698859 | SGD     |\n",
      "| DEFAULT_08cf9_00003 | ERROR    |       |           8 |   64 |   64 |  128 |    4 | 0.0012677   | Adam    |\n",
      "| DEFAULT_08cf9_00004 | ERROR    |       |          16 |   32 |   64 |  256 |    4 | 0.0018342   | SGD     |\n",
      "| DEFAULT_08cf9_00005 | ERROR    |       |          16 |   64 |  128 |   64 |    8 | 0.000544801 | Adam    |\n",
      "| DEFAULT_08cf9_00006 | ERROR    |       |           8 |   16 |   64 |  128 |   32 | 0.000772192 | SGD     |\n",
      "| DEFAULT_08cf9_00007 | ERROR    |       |           2 |   32 |  128 |   64 |   16 | 0.000262082 | Adam    |\n",
      "| DEFAULT_08cf9_00008 | ERROR    |       |          16 |   16 |   64 |  256 |  256 | 0.0333098   | Adam    |\n",
      "| DEFAULT_08cf9_00009 | ERROR    |       |           4 |   32 |   64 |  128 |   16 | 0.0158023   | SGD     |\n",
      "+---------------------+----------+-------+-------------+------+------+------+------+-------------+---------+\n",
      "Number of errored trials: 10\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                             |\n",
      "|---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| DEFAULT_08cf9_00000 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00000_0_batchsize=8,c1=32,c2=32,c3=256,l1=64,lr=0.00050722,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00001 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00001_1_batchsize=4,c1=64,c2=128,c3=128,l1=4,lr=0.0024119,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00002 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00002_2_batchsize=16,c1=16,c2=128,c3=256,l1=256,lr=0.00069886,optim=SGD_2020-10-10_12-20-50/error.txt |\n",
      "| DEFAULT_08cf9_00003 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00003_3_batchsize=8,c1=64,c2=64,c3=128,l1=4,lr=0.0012677,optim=Adam_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00004 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00004_4_batchsize=16,c1=32,c2=64,c3=256,l1=4,lr=0.0018342,optim=SGD_2020-10-10_12-20-50/error.txt     |\n",
      "| DEFAULT_08cf9_00005 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00005_5_batchsize=16,c1=64,c2=128,c3=64,l1=8,lr=0.0005448,optim=Adam_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00006 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00006_6_batchsize=8,c1=16,c2=64,c3=128,l1=32,lr=0.00077219,optim=SGD_2020-10-10_12-20-50/error.txt    |\n",
      "| DEFAULT_08cf9_00007 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00007_7_batchsize=2,c1=32,c2=128,c3=64,l1=16,lr=0.00026208,optim=Adam_2020-10-10_12-20-50/error.txt   |\n",
      "| DEFAULT_08cf9_00008 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00008_8_batchsize=16,c1=16,c2=64,c3=256,l1=256,lr=0.03331,optim=Adam_2020-10-10_12-33-07/error.txt    |\n",
      "| DEFAULT_08cf9_00009 |            1 | /home/ec2-user/ray_results/DEFAULT/DEFAULT_08cf9_00009_9_batchsize=4,c1=32,c2=64,c3=128,l1=16,lr=0.015802,optim=SGD_2020-10-10_12-34-08/error.txt      |\n",
      "+---------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [DEFAULT_08cf9_00000, DEFAULT_08cf9_00001, DEFAULT_08cf9_00002, DEFAULT_08cf9_00003, DEFAULT_08cf9_00004, DEFAULT_08cf9_00005, DEFAULT_08cf9_00006, DEFAULT_08cf9_00007, DEFAULT_08cf9_00008, DEFAULT_08cf9_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-64373361a666>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         progress_reporter=reporter)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [DEFAULT_08cf9_00000, DEFAULT_08cf9_00001, DEFAULT_08cf9_00002, DEFAULT_08cf9_00003, DEFAULT_08cf9_00004, DEFAULT_08cf9_00005, DEFAULT_08cf9_00006, DEFAULT_08cf9_00007, DEFAULT_08cf9_00008, DEFAULT_08cf9_00009])"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
